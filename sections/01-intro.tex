%!TEX root = ../main.tex
\section{Introduction} 
\label{sec:intro}

%As Internet of Things (IoT) and 5G communication technologies are widely commercialized, massive data are collected, stored and analyzed. The traditional architecture of data infrastructure at data centers has been challenged by cloud-native designs. Compute and storage resources are pooled to be able to serve massive structured and unstructured data in an elastic and cost-efficient manner.  Analytical systems such as data warehouses and big data platforms have also evolved from siloed construction to disaggregated storage and compute architecture with horizontal integration of resource pools. Thanks to its 10x better price, availability and persistence compared to traditional storage formats, data lake storage [4] becomes a de facto cost-friendly storage layer in this architecture, storing massive online and offline data captured for large scale data analysis. Enterprise data engineers and analysts can easily use data lake storage implementation such as AWS S3~\cite{} or Huawei OceanStor Pacific~\cite{} as an affordable and reliable centralized pool of storage to save full data. On top of it, they build data preparation and analytics pipelines to assist business decision making, serve customers and meet compliance requirements. 

As the Internet of Things (IoT) and 5G communication technologies become increasingly prevalent, massive amounts of data are being collected, stored, and analyzed.
 The traditional architecture of data infrastructure  has been challenged by cloud-native designs, where compute and storage resources are pooled to serve massive structured and unstructured data in an elastic and cost-efficient manner.
  Analytical systems such as data warehouses and big data platforms have also evolved from siloed~\footnote{a term?} constructions to disaggregated storage and compute architectures. For example, data lake storage~\cite{}, with its 10$\times$ better price, availability, and persistence compared to traditional storage formats, has been very popular for storing massive online and offline data captured, so as to support large-scale data analysis.
  \cc{what is the connection with the next? data lake storage?}
   Enterprise data analysts can easily leverage data lake storage implementations such as AWS S3~\cite{} or Huawei OceanStor Pacific~\cite{} as a reliable centralized  storage pool, on top of which  data preparation and analytical pipelines are built.

However, as large enterprises further digitalize their business, the data to be stored and analyzed explode. The management costs rise rapidly and become a heavy burden. For instance, 4.8 petabytes fresh data flow into data lakes daily for storage and analysis in China Mobile, the world's largest mobile network operator, and the existing architectures of analytic systems are inapt to scale and process petabytes of data gracefully. Hence, expensive additional operations have to be introduced to support analytic needs. Similarly, we have observed the same situation in other large cooperate customers which Huawei closely works with. A large amount of resources and costs have to be added as the analytic system scales. Although storage increase is inevitable as data grow, a large portion of the cost increases in the analytic systems is because compute engines in data pipelines fail to share data management properly. Hence, massive server resources are wasted in data transfers, re-computing and re-storing intermediate states across engines even though these engines may use same data inputs.


%As large enterprises continue to digitize their businesses, the amount of data to be stored and analyzed is growing exponentially. This results in significant management costs that can become a heavy burden. For example, China Mobile, the world's largest mobile network operator, receives 4.8 petabytes of fresh data every day for storage and analysis. However, existing analytic systems are not equipped to handle petabytes of data gracefully. This means that expensive additional operations must be introduced to support analytic needs. This same situation is observed in other large corporate customers that Huawei closely works with, where a significant amount of resources and costs must be added as the analytic system scales. While storage increases are inevitable as data grows, a significant portion of the cost increases in analytic systems is due to compute engines in data pipelines failing to share data management properly. As a result, massive server resources are wasted in data transfers, re-computing, and re-storing intermediate states across engines, even though these engines may use the same data inputs.

To address this common problem of big data platforms in enterprise production environments, researchers and engineers in our data management community have evolved existing compute engines or designed new system components to converge data pipelines and enhance data re-usage. For example, first, unified engines~\cite{} for stream and batch processing as well as lakehouse technologies~\cite{} with ACID-compliant transactions are developed. These approaches are closely tied to a specific compute engine, optimizing an end-to-end process with a point view. However, in order to cover various business analytical needs, enterprise production data pipelines need close collaboration between multiple analytic tools. Hence, rather optimizing for a single step or module, it requires us to take an end-to-end view to make effective collaborative optimizations in real world. Second, in the modern cloud-native storage-disaggregated architecture, network overhead is expensive if we maintain a shared state layer in the compute cluster which requires frequent and massive data accesses to the storage. Third, separating data management from the storage layer misses the opportunities to apply advanced storage technologies~\cite{} which are critical to process massive data cost-effectively. Finally, data layout management strategies such as compaction and partitioning are key to ensure overall storage utilization and query performance. Existing approaches~\cite{} normally apply static or manual methods to compact small files or manage data partitions. This is sub-optimal compared to dynamic self-learning algorithms in production with complex data pipelines and massive data. We argue that it is reasonable to dedicate the data management component to the storage side and intelligently optimize it on top of the data lake persistent storage to enable shortest dataflows and to maximize the potential of data re-usage across engines in a cost-efficient and collaborative manner.


In this paper, we present a data lake storage framework, StreamLake, with its novel design to support massive message stream ingestion and data pipeline co-processing. This framework provides community compatible API for message stream processing, allowing inflow messages to bypass the compute layer and to be injected to the data lake storage cluster directly. It also supports ACID-compliant transactions, query time-travel, and query operator pushdowns to minimize data transfer and maximize data sharing. A new data lake optimizer is introduced where reinforcement learning and probabilistic network algorithms are applied to data layout management to optimize query time and server resource usage. All these features are built on top of the Huawei OceanStor Pacific storage and the system applies advanced capabilities in the Huawei storage such as in-cluster RDMA network, tiered storage, erasure coding and instant snapshot~\cite{} to achieve superior system resource utilization with reasonable costs. With this centralized stateful storage, analytic engine instances can be more elastic and hence server resources can be highly utilized. We have experimented this framework in a China Mobile data lake with 20 petabytes of data. The system has demonstrated significant server usage gains. We conclude our contributions as follows:

We propose a novel design of a data lake storage co-processing framework to unify log message streaming, processing and querying acceleration in disaggregated data lake storage, improving both the resource utilization and the speed of data processing pipelines in scale.


We design a scalable message stream storage with separated control and data planes. It offers ecosystem-compatible messaging system APIs and is highly scalable and reliable, being able to directly consume billions of records with cost-efficient tiered persistent storages. 


We extend the message streaming service to support lakehouse data formats for query concurrent processing. It provides lakehouse tabular abstraction to computing engines to concurrently access millions of records as ACID-compliant tables, improving the granularity of the data usage significantly.


We introduce a new data lake optimizer in storage. It applies reinforcement learning and probabilistic network algorithms with storage characteristics and query history to optimize the data layout dynamically, optimizing both the query time and the storage block utilization.

We conduct a use case study with the China mobile IT team to evaluate the StreamLake implementation. Compared to the current system, the experiments show that the new design brings in 39\% to 4x resource usage and performance gains.

%The rest of this paper is organized as follows. Section 2-6 detail the motivation, design and implementation of key components such like the stream storage, the lakehouse framework and the data lake optimizer. Section 7 discusses the experiments. Section 8 compares related work. Conclusions are drawn in Section 9.
