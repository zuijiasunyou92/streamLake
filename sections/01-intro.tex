%!TEX root = ../main.tex
\section{Introduction} 
\label{sec:intro}

%As Internet of Things (IoT) and 5G communication technologies are widely commercialized, massive data are collected, stored and analyzed. The traditional architecture of data infrastructure at data centers has been challenged by cloud-native designs. Compute and storage resources are pooled to be able to serve massive structured and unstructured data in an elastic and cost-efficient manner.  Analytical systems such as data warehouses and big data platforms have also evolved from siloed construction to disaggregated storage and compute architecture with horizontal integration of resource pools. Thanks to its 10x better price, availability and persistence compared to traditional storage formats, data lake storage [4] becomes a de facto cost-friendly storage layer in this architecture, storing massive online and offline data captured for large scale data analysis. Enterprise data engineers and analysts can easily use data lake storage implementation such as AWS S3~\cite{} or Huawei OceanStor Pacific~\cite{} as an affordable and reliable centralized pool of storage to save full data. On top of it, they build data preparation and analytics pipelines to assist business decision making, serve customers and meet compliance requirements. 

As the Internet of Things (IoT) and 5G communication technologies become increasingly prevalent, massive amounts of data are being collected, stored, and analyzed.
 The traditional architecture of data infrastructure  has been challenged by cloud-native designs, where compute and storage resources are pooled to serve massive structured and unstructured data in an elastic and cost-efficient manner.
  Analytical systems such as data warehouses and big data platforms have also evolved from siloed~\footnote{a term?} constructions to disaggregated storage and compute architectures. For example, data lake storage ($e.g.,$ AWS S3~\cite{}, Huawei OceanStor Pacific~\cite{}), with its 10$\times$ better price, availability, and persistence compared to traditional storage formats, has been very popular for storing massive various data, so as to support large-scale data analysis.


However, as large enterprises further digitalize their business, the data to be stored and analyzed explode. Over the past several years, we have collaborated closely with over 200 enterprise customers from 16 different industries to better understand their big data processing requirements. Our analysis of key statistics has revealed the following insights:

\noindent \underline{\textit{Petabytes of data.}} Nearly half of our customers (49\%) have processed data ranging from one terabyte to 10 petabytes (PB). A significant percentage (29\%) handle more than 10 PB, while 8\% manage over 100 PB of data.


\noindent \underline{\textit{Log data.}} A large majority (81\%) of our customers primarily work with log message data.

\noindent \underline{\textit{Stream and batch processing.}} Both stream and batch processing play a critical role in big data processing. 69\% of  customers actively use batch processing, and 65\% use stream processing. Nearly 40\%  care about both. 
Also, when processing data through data pipelines, in many cases, customers  have to continuously  update the datasets.

\noindent \underline{\textit{Data retention.}} In practice, 43\% customers are required to store data between 1 and 5 years. 22\% store between 5 and 10 years and 27\% store at least 10 years, according to regulations and practices in different industries.


To satisfy the above users' requirements, we aim to design a data lake storage system to support stream and batch data co-processing with high efficiency, persistence, scalability and low Total Cost Ownership (TCO). To this end, the system has several significant aspects  to be considered. (1) As users always face petabytes of log streaming data, it is challenging to store the data persistently at low cost, while keeping high scalability and processing efficiency. For example, as streaming data needs real-time processing,  typical system like Kafka uses local file system as the storage, which lacks of scalibility capacity because the computation and storage are tightly coupled. Also, in practice, given the same data, over which users may conduct stream or batch processing for different applications, thus storing two copies for different processes is costly.
 %流的存储很贵，因为要实时处理，所以计算存储强耦合，不能各自scale。扩的时候一起扩，会贵。 
 %分叉了不好办，改了一个影响另一个
% If one considers to store as stream data, and convert it to batch when batch processing is necessary, it will be time-consuming to load the data to the compute engine and conduct the conversion.	
% 数据有多个备份(multiple copy) 更新自己备份 别人不aware 导致数据不一致 delta lake video
(2) In a data analysis pipeline, there are likely to be multiple copies when data goes through the pipeline. If these copies are updates individually, data  will be corrupted because   they are not aware of the updates.   
 Hence, it is significant to support atomic writes to achieve high quality data.
  \cc{does the metadata read latency has relation with the copies?}
%元数据读取时间长
(3) In data lake storage, compute-and-storage \cc{disaggregated} architecture  is applied for scalability,  and thus it is challenging to perform an end-to-end optimization like in a database. Hence, it is critical to consider how to incorporate an optimizer in the storage engine, so as to optimize the query performance and resource utilization.

% 









%The management costs rise rapidly and become a heavy burden. For instance, 4.8 petabytes fresh data flow into data lakes daily for storage and analysis in China Mobile, the world's largest mobile network operator, and the existing architectures of analytic systems are inapt to scale and process petabytes of data gracefully. Hence, expensive additional operations have to be introduced to support analytic needs. Similarly, we have observed the same situation in other large cooperate customers which Huawei closely works with. A large amount of resources and costs have to be added as the analytic system scales. Although storage increase is inevitable as data grow, a large portion of the cost increases in the analytic systems is because compute engines in data pipelines fail to share data management properly. Hence, massive server resources are wasted in data transfers, re-computing and re-storing intermediate states across engines even though these engines may use same data inputs.


%As large enterprises continue to digitize their businesses, the amount of data to be stored and analyzed is growing exponentially. This results in significant management costs that can become a heavy burden. For example, China Mobile, the world's largest mobile network operator, receives 4.8 petabytes of fresh data every day for storage and analysis. However, existing analytic systems are not equipped to handle petabytes of data gracefully. This means that expensive additional operations must be introduced to support analytic needs. This same situation is observed in other large corporate customers that Huawei closely works with, where a significant amount of resources and costs must be added as the analytic system scales. While storage increases are inevitable as data grows, a significant portion of the cost increases in analytic systems is due to compute engines in data pipelines failing to share data management properly. As a result, massive server resources are wasted in data transfers, re-computing, and re-storing intermediate states across engines, even though these engines may use the same data inputs.


To address these issues, we deploy our \sys system with its novel design to serve enterprise-level  \cc{massive message stream ingestion and data pipeline co-processing.}


First, in terms of the streaming storage,
%存储层 分发层的分离，stream object，读写流消息。
 we introduce the \textit{stream object}  to provide efficient stream storage and access. It designs the read/write interfaces to support real-time streaming by \cc{XXX (for read), XXX (for write)}. 
To achieve cost-effective stream and batch co-processing, we also design the \textit{table object} that can be automatically converted  to the \textit{stream object}, and vice versa. In this way, data can be maintained for just one copy rather than storing for two copies separately, and thus the storage cost is reduced. 
Existing works~\cc{\cite{}}, but \cc{XX}.
%自动分级 自动分成冷存储，转成表格式




Second, in terms of supporting updates, Lakehouse system~\cite{} can address this by achieving concurrent read and write in an ACID manner. We also implement the lakehouse functionality in \sys to supports ACID for \cc{both stream and batch data.} Particularly, we design a global write cache that ~\cc{combines small I/O access}, so as to~\cc{XX}.
%元数据是大量小文件读写 

Third, for storage-side optimization, we build an intelligent data lake optimizer \brain that focuses on optimizing the data layout in the storage.%resource utilization + query performance
 To be specific, a reinforcement learning based automatic compaction module is designed to decide whether to compact small files considering the system state, so as to \cc{improve the block utilization while keeping the system running smoothly.} Besides, a predicate-aware partitioning model is utilized to judiciously distribute data to storage blocks to reduce the number of blocks to be visited, so as to improve the query efficiency.  Existing works~\cc{\cite{}},

Overall, our \sys has the following characteristics.


\noindent \underline{\textit{High processing efficiency.}} 


\noindent \underline{\textit{High storage scalability.}}


\noindent \underline{\textit{Low TCO.}} 


\noindent \underline{\textit{High reliability.}}

\noindent \textbf{Use case.} To satisfy the user requirements by achieving the above goals, we build a storage system \sys that \cc{XXX} and deploy it in China Mobile data lakes with production data, \cc{resulting in significant optimization of ?resource utilization?.}  China Mobile manages one of the largest data analytic platforms in China.
Over 4.8 petabytes \cc{per day?} of fresh data flow from business branches and edge devices scattered across over 30 provinces to several centralized data centers. The fresh data first lands on a collection and exchange platform where data exchanges across data centers. Then it is loaded into the analytic platform. Data warehouse and big data engines run billions of jobs  over the data to provide location services, network logging analysis and many other applications to serve users.
As the platform grew to the exabyte scale, \cc{resource utilization} became increasingly skewed, with average CPU, memory, and storage utilizations at \cc{26\%, 41\%, and 66\%} respectively.




To overcome this, we deployed StreamLake in a China Mobile data center with 20 petabytes of production data, replacing the existing analytic architecture with a disaggregated-storage architecture powered by Huawei OceanStor Pacific with  \sys framework.\cc{Moderate changes are applied to connect the analytic engines to StreamLake.}

\cc{The evaluation shows a significant improvement of resource utilization.}
\sys runs the same number of analytic jobs with 39\% less servers, due to the high utilization of \cc{data and server resources} in \sys. Besides, \sys also introduces  benefits in term of performance and service flexibility. For instance, some batch queries can speed up to 4 times when the query operator pushdown and the \brain are enabled. 
For message streaming, originally, they had to maintain 300 more \kafka servers, and the expansion of partitions and nodes posed a big challenge to the China Mobile IT team. With the stream storage in StreamLake, the team no longer needs to \cc{manually} manage the Kafka servers. In addition, minimum data migration is required to scale the system, and thus maintenance costs are thus greatly reduced. 

\cc{which factors are shown in the exp figure??}


\cc{The structural figure is necessary??}

 
 
 
 
 
 
 \iffalse

To address this common problem of big data platforms in enterprise production environments, researchers and engineers in our data management community have evolved existing compute engines or designed new system components to converge data pipelines and enhance data re-usage. For example, first, unified engines~\cite{} for stream and batch processing as well as lakehouse technologies~\cite{} with ACID-compliant transactions are developed. These approaches are closely tied to a specific compute engine, optimizing an end-to-end process with a point view. However, in order to cover various business analytical needs, enterprise production data pipelines need close collaboration between multiple analytic tools. Hence, rather optimizing for a single step or module, it requires us to take an end-to-end view to make effective collaborative optimizations in real world. Second, in the modern cloud-native storage-disaggregated architecture, network overhead is expensive if we maintain a shared state layer in the compute cluster which requires frequent and massive data accesses to the storage. Third, separating data management from the storage layer misses the opportunities to apply advanced storage technologies~\cite{} which are critical to process massive data cost-effectively. Finally, data layout management strategies such as compaction and partitioning are key to ensure overall storage utilization and query performance. Existing approaches~\cite{} normally apply static or manual methods to compact small files or manage data partitions. This is sub-optimal compared to dynamic self-learning algorithms in production with complex data pipelines and massive data. We argue that it is reasonable to dedicate the data management component to the storage side and intelligently optimize it on top of the data lake persistent storage to enable shortest dataflows and to maximize the potential of data re-usage across engines in a cost-efficient and collaborative manner.


In this paper, we present a data lake storage framework, StreamLake, with its novel design to support massive message stream ingestion and data pipeline co-processing. This framework provides community compatible API for message stream processing, allowing inflow messages to bypass the compute layer and to be injected to the data lake storage cluster directly. It also supports ACID-compliant transactions, query time-travel, and query operator pushdowns to minimize data transfer and maximize data sharing. A new data lake optimizer is introduced where reinforcement learning and probabilistic network algorithms are applied to data layout management to optimize query time and server resource usage. All these features are built on top of the Huawei OceanStor Pacific storage and the system applies advanced capabilities in the Huawei storage such as in-cluster RDMA network, tiered storage, erasure coding and instant snapshot~\cite{} to achieve superior system resource utilization with reasonable costs. With this centralized stateful storage, analytic engine instances can be more elastic and hence server resources can be highly utilized. We have experimented this framework in a China Mobile data lake with 20 petabytes of data. The system has demonstrated significant server usage gains. We conclude our contributions as follows:

We propose a novel design of a data lake storage co-processing framework to unify log message streaming, processing and querying acceleration in disaggregated data lake storage, improving both the resource utilization and the speed of data processing pipelines in scale.


We design a scalable message stream storage with separated control and data planes. It offers ecosystem-compatible messaging system APIs and is highly scalable and reliable, being able to directly consume billions of records with cost-efficient tiered persistent storages. 


We extend the message streaming service to support lakehouse data formats for query concurrent processing. It provides lakehouse tabular abstraction to computing engines to concurrently access millions of records as ACID-compliant tables, improving the granularity of the data usage significantly.


We introduce a new data lake optimizer in storage. It applies reinforcement learning and probabilistic network algorithms with storage characteristics and query history to optimize the data layout dynamically, optimizing both the query time and the storage block utilization.

We conduct a use case study with the China mobile IT team to evaluate the StreamLake implementation. Compared to the current system, the experiments show that the new design brings in 39\% to 4x resource usage and performance gains.

\fi

%The rest of this paper is organized as follows. Section 2-6 detail the motivation, design and implementation of key components such like the stream storage, the lakehouse framework and the data lake optimizer. Section 7 discusses the experiments. Section 8 compares related work. Conclusions are drawn in Section 9.
