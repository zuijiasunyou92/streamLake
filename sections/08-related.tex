%!TEX root = ../main.tex
\section{Related Work} 
\label{sec:related}


In this section, we will discuss relevant open-source projects and systems related to \sys $w.r.t.$ \cc{streaming platforms}, lakehouse data management, query computation pushdown and automatic database tuning.

\noindent\textbf{Streaming platforms.} Kafka, Pulsar and Pravega~\cite{} are widely-used open-source streaming platforms in industry. Unlike \sys, which builds its messaging service on top of the stream object and PLogs, and integrates its stream storage with a lakehouse framework, these solutions are file-based and require manual connections to compute engines and external storage, such as \hdfs~\cite{} or \texttt{S3}~\cite{}, for downstream processing or cost-friendly archiving. This increases both the complexity and cost of data pipeline management.



\noindent\textbf{Lakehouse.} Iceberg, Hudi and Delta Lake~\cite{} are popular  lakehouse data management framework, which rely on statistic file or object storage. 
Massive data transmission between the storage and the compute engines are inevitable in many scenarios. \cc{Not coherent!!!}
 \sys builds the lakehouse framework on top of the table object and PLogs, leveraging the enterprise-level data redundancy, high performance cache and query computation pushdown to provide reliable and high speed concurrent lakehouse reads/writes. 


\cc{Below is hard to follow!}

\noindent\textbf{Query computation pushdown.} NetApp~\cite{} supports Hadoop to use its storage devices through NFS-based connector docking, through S3A docking to its object storage, and through SAS/iSCSI/FC building native \hdfs on its block/lun devices. AWS EMRFS~\cite{} is an enhancement introduced to address the inconsistency of object storage in metadata operations, with official information showing that it has made computation pushdown related optimizations for the engine. Alibaba EMR is based on object storage, and the JindoFS~\cite{} solves the performance problem of object storage by introducing local data caching. These solutions improve data access to the persistent storage in computation pushdown while StreamLake offers built-in computation pushdown operations directly. 

\noindent\textbf{Automatic database tuning .} In term of automatic database tuning systems, OtterTune [40] is a classic ML-based framework, recommending knob configuration using Gaussian process (GP). To address the limitation of traditional ML-based approaches, RL has been adopted in CDBTune [44]. Investigated in [41] shows the impact of the performance variation in production environments, indicating that GP tends to converge faster but is frequently trapped in local optima, whereas RL or deep learning (DL) generally needs a longer training process and achieves better performance.  [37] is the first approach that tries to maximize data skipping for a partitioning using pushdown predicates with a bottom-up approach. QDTree [43] proposed a greedy algorithm and a reinforcement learning based algorithm to solve the data skipping maximization problem to solve the suboptimal limitation. However, these algorithms need to quantify the performance of each candidate partitioning. In addition, the partitioning layout is sub-optimal when new data comes, as it is optimized based on existing data.