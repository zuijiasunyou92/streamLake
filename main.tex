% VLDB template version of 2020-08-03 enhances the ACM template, version 1.7.0:
% https://www.acm.org/publications/proceedings-template
% The ACM Latex guide provides further information about the ACM template

\documentclass[sigconf, nonacm]{acmart}

%% The following content must be adapted for the final version
% paper-specific
\newcommand\vldbdoi{XX.XX/XXX.XX}
\newcommand\vldbpages{XXX-XXX}
% issue-specific
\newcommand\vldbvolume{14}
\newcommand\vldbissue{1}
\newcommand\vldbyear{2020}
% should be fine as it is
\newcommand\vldbauthors{\authors}
\newcommand\vldbtitle{\shorttitle} 
% leave empty if no availability url should be set
\newcommand\vldbavailabilityurl{URL_TO_YOUR_ARTIFACTS}
% whether page numbers should be shown or not, use 'plain' for review versions, 'empty' for camera ready
\newcommand\vldbpagestyle{plain} 


\input{sections/commands}

\begin{document}
\title{Separation Is for Better Reunion: Data Lake Storage at Huawei}

%%
%% The "author" command and its associated commands are used to define the authors and their affiliations.
\iffalse
\author{Ben Trovato}
\affiliation{%
  \institution{Institute for Clarity in Documentation}
  \streetaddress{P.O. Box 1212}
  \city{Dublin}
  \state{Ireland}
  \postcode{43017-6221}
}
\email{trovato@corporation.com}
\fi



%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Huawei collaborates with some  Chinese large business companies to store and process exabytes of nationwide operational data in data lake storage to provide business insights.  
 Specifically, our customers will ask to store  and process massive  log message data to support their real-time and  decision making applications. Thus, we need compute and storage components in the analytic platform  to process and store these data cost-efficiently. 


%This process involves handling nation-scale streams and batch data processing with massive static server resources, which requires compute and storage components in the analytic platform  to process and store massive data cost-efficiently. 


 %However, existing solutions are sub-optimal due to \cc{inevitable data isolation and copies in compute-engine-oriented designs.}
 

 To meet these user requirements, we have designed a data lake storage system, \sys, which introduces a novel  design to serve log message streaming and batch data processing  in distributed storage, with high scalability, efficiency, reliability and low cost. 
 Specifically, we introduce a stream object as a storage abstraction for streaming data to achieve the storage-disaggregation architecture with high scalability and reliability. Moreover, we utilize the erasure coding and tiring storage to save the storage cost, and furthermore, the  stream object can be automatically converted to table object such that cost-effective stream and batch data processing can be achieved. For tabular data, we support the lakehouse functionality  to support ACID via the table object, with a metadata cache to improve the efficiency of data access between compute and storage engine.  Also, we design a \brain optimizer at the storage side to optimize the query performance and resource utilization under the storage-disaggregation architecture.
 %Data intensive operations such as message streaming, query operator pushdown, transaction and query time travel are managed inside the centralized disaggregated storage cluster to minimize data copies and shorten time windows in analytic pipelines.
 % Storage features such as multi-level caches and erasure coding along with algorithms like reinforcement learning and probabilistic network are also applied in \sys to further optimize query time and resource usage. 
  Finally, we have also deployed  \sys in China Mobile, the world's largest mobile network operator  to serve over 20\texttt{PB} production data, and the results demonstrate improvements of 30\% to $4\times$ in terms of query performance and over 37\% in terms of cost saving.
\end{abstract}

%Huawei collaborates with some of China's largest business companies to manage and analyze vast amounts of nationwide operational data in data lake storage. This process involves handling nation-scale streams of updates and static server resources, which necessitates the use of sub-systems within the analytic platform to efficiently utilize and share enormous amounts of data. However, existing solutions are suboptimal due to the isolation and duplication of data in compute-engine-oriented designs.

%To address this problem, Huawei has developed an experimental data lake storage system called StreamLake. StreamLake introduces a unique design that supports log message streaming and ETL processing acceleration in distributed storage. To minimize data copies and shorten time windows in analytic pipelines, StreamLake manages data-intensive operations such as message streaming, query operator pushdown, transaction, and query time travel inside a centralized disaggregated storage cluster.

%Furthermore, StreamLake implements storage features such as multi-level caches and erasure coding, as well as algorithms like reinforcement learning and probabilistic networks, to further optimize query time and resource usage. Huawei has tested this framework using production data from China Mobile, the world's largest mobile network operator, and the results demonstrate significant improvements in terms of performance, server resource gains, and query time optimization, ranging from 30% to 4x and over 39%, respectively.

\maketitle

%%% do not modify the following VLDB block %%
%%% VLDB block start %%%
\iffalse
\pagestyle{\vldbpagestyle}
\begingroup\small\noindent\raggedright\textbf{PVLDB Reference Format:}\\
\vldbauthors. \vldbtitle. PVLDB, \vldbvolume(\vldbissue): \vldbpages, \vldbyear.\\
\href{https://doi.org/\vldbdoi}{doi:\vldbdoi}
\endgroup
\begingroup
\renewcommand\thefootnote{}\footnote{\noindent
This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit \url{https://creativecommons.org/licenses/by-nc-nd/4.0/} to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing \href{mailto:info@vldb.org}{info@vldb.org}. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. \\
\raggedright Proceedings of the VLDB Endowment, Vol. \vldbvolume, No. \vldbissue\ %
ISSN 2150-8097. \\
\href{https://doi.org/\vldbdoi}{doi:\vldbdoi} \\
}\addtocounter{footnote}{-1}\endgroup
\fi
%%% VLDB block end %%%

%%% do not modify the following VLDB block %%
%%% VLDB block start %%%

%%% VLDB block end %%%


\input{sections/01-intro}
%\input{sections/02-motivation}
\input{sections/03-archi}
\input{sections/04-storage}
\input{sections/05-dataprocessing}
\input{sections/06-optimization}
\input{sections/07-exp}
\input{sections/08-related}
\input{sections/09-conclusion}



\newpage


%\begin{acks}
% This work was supported by the [...] Research Fund of [...] (Number [...]). Additional funding was provided by [...] and [...]. We also thank [...] for contributing [...].
%\end{acks}

%\clearpage

\normalem
\bibliographystyle{ACM-Reference-Format}
\bibliography{bib/ref}

\end{document}
\endinput
